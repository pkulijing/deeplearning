\ifx\PREAMBLE\undefined
\input{preamble}
\begin{document}
\fi
\chapter{Structuring Machine Learning Projects}
\section{Introduction to ML Strategy}
A lot of options are available when it comes to improving the performance of a ML model:
\begin{itemize}
  \item Collect more data
  \item Collect more diverse training set
  \item Train algorithm longer with gradient descent
  \item Try Adam instead of gradient descent
  \item Add L2 / dropout regularization
  \item Change network architecture: activation function, \# hidden units, bigger / smaller network
\end{itemize}
Machine Learning strategy helps to find the most promising direction to proceed.
\subsection{Orthogonalization}
Chain of assumptions in ML:
\begin{enumerate}
  \item Fit training set well on cost function (human level performance): bigger network; better optimization algorithm
  \item Fit dev set well on cost function: regularization; bigger train set
  \item Fit test set well on cost function: bigger dev set
  \item Perform well in real world: change dev set; change cost function
\end{enumerate}
If the model's performance is not ideal in one stage, there exists specific approaches to take for better performance of that stage.

Early stopping is a strategy against the orthogonalization principle: it trys to ameliorate the performance on both the train set and dev set at the same time.
\subsection{Goal Setup}
\subsubsection{Single Number Evaluation Metric}
Use appropriate metrics that can be expressed by a single number for easier tuning.

Precision $P$ \& recall $R$ $\rightarrow$ F1 score = $\frac{2}{1/P+1/R}=\frac{2PR}{P+R}$
\subsubsection{Satisficing \& Optimizing Metrics}
\begin{itemize}
  \item optimizing metric: a metric to optimize as well as possible
  \item satisficing metric: a metric that is acceptable as long as some limit is satisfied
\end{itemize}
e.g. 
\begin{itemize}
  \item For cat recognization: accuracy is optimizing metric, while running time is satisficing metric (as long as $<100ms$, it is acceptable)
  \item Waking word of smart speaker: accuracy is optimizing metric, while false positive frequency is satisficing metric (at most 1 each day).
\end{itemize}
\subsubsection{Train/Dev/Test Set Setup}
\begin{itemize}
  \item Distribution: choose dev \& test set to reflect real world data. Make sure they come from the same distribution.
  \item Size: test set should be big enough to give high confidence in the overall performance of the system. 70/30 or 60/20/20 for small dataset, 98/1/1 for big dataset.
\end{itemize}
\subsubsection{When to Change}
If doing well with metric + dev/set data does not lead to good real world performance, consider to change the metric and/or dev/test set. For example, apply extra weight to a certain type of prediction error that is absolutely inteloratable:
\[\frac{1}{m_{dev}}\displaystyle\sum_{i=1}^{m_{dev}}\mathbf{1}\left(y^{(i)}_{pred}\neq y^{(i)}\right)\Rightarrow\frac{1}{\sum_{i=1}^{m_{dev}}w_i}\displaystyle\sum_{i=1}^{m_{dev}}w_i\mathbf{1}\left(y^{(i)}_{pred}\neq y^{(i)}\right)\]
\subsection{Human-Level Performance}
\subsubsection{Why Human-level Performance}
We would like to compare our model with human-level performance because humans are quite good at a lot of tasks. When our ML model is worse than humans, we can 
\begin{itemize}
  \item Get labeled data from humans
  \item Gain insight from manual error analysis: why did a person get this right?
  \item Better analysis of bias / variance
\end{itemize}
\subsubsection{Avoidable Bias}
Human-level performance can often be used as a good estimation of Bayes Optimal Error, which is the theoretically best possible error one can achieve. The difference between the train error and human-level performance is called the avoidable bias. When the gap is large, we diagnose the model as having high bias and should try to reduce the train error. Whereas when this gap is small and the gap between the train error and the dev error is relatively large, we should try to reduce the dev error to reduce variance.

People with professional background tend to do better at certain tasks. Even better results can be achieved by collective work of a group of such professionals. Human-level performance of a task should take the value the best achievable result so that it can be viewed as a good estimation of the Bayes optimal error to guide our development.
\subsubsection{Surpassing Human-Level Performance}
ML significantly surpasses human-level performance when it comes to dealing with large amounts of structured data:
\begin{itemize}
\item Online advertising
\item Product recommendations
\item Logistics (predicting transit time)
\item Loan approvals
\end{itemize}
Recently, ML is even reported to behave better than human at some tasks in which humans are really good at:
\begin{itemize}
  \item speech recognition
  \item some computer vision tasks
  \item medical applications: ECG, skin cancer diagnosis
\end{itemize}
\subsubsection{Improving Model Performance}
Fundamental assumptions of supervised learning:
\begin{itemize}
  \item The training set can be fitted really well: reduce avoidable bias
  \item The training set performance generalizes pretty well to the dev/test sets: reduce variance
\end{itemize}
The gap between human-level and the training error indicates the avoidable bias. Possible approaches to reduce it: train a bigger model; train longer; use better algorithms; try different NN architectures; hyperparameter search; etc.

The gap between the training error and the dev error indicates the variance. Possible approaches to reduce it: get more data; regularization(L2, dropout, data augmentation); try different NN archiitectures; etc.
\ifx\PREAMBLE\undefined
\end{document}
\fi